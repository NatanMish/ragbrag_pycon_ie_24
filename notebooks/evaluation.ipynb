{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluation\n",
    "\n",
    "### Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/ragbrag_pycon_ie_24/venv/lib/python3.10/site-packages/deepeval/__init__.py:49: UserWarning: You are using deepeval version 1.2.9, however version 1.3.5 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n",
      "/Users/user/Projects/ragbrag_pycon_ie_24/venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.schema import BaseNode, TransformComponent\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "import faiss\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import pickle\n",
    "import json\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval, FaithfulnessMetric, ContextualRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCaseParams, LLMTestCase\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "EMBED_DIMENSION = 512\n",
    "CHUNK_SIZE = 200\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=EMBED_DIMENSION)\n",
    "\n",
    "path = \"../data/\"\n",
    "node_parser = SimpleDirectoryReader(input_dir=path, required_exts=['.txt', '.pdf'])\n",
    "documents = node_parser.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up vector store retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(TransformComponent):\n",
    "    \"\"\"\n",
    "    Transformation to be used within the ingestion pipeline.\n",
    "    Cleans clutters from texts.\n",
    "    \"\"\"\n",
    "    def __call__(self, nodes, **kwargs) -> List[BaseNode]:\n",
    "        \n",
    "        for node in nodes:\n",
    "            node.text = node.text.replace('\\t', ' ') # Replace tabs with spaces\n",
    "            node.text = node.text.replace(' \\n', ' ') # Replace paragraph seperator with spacaes\n",
    "            \n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored hash: c2f153cb42cbd31a2daab16f31f19d1d, current hash: c2f153cb42cbd31a2daab16f31f19d1d\n",
      "Loading vector store from cache...\n"
     ]
    }
   ],
   "source": [
    "CACHE_DIR = \"../cache\"\n",
    "VECTOR_STORE_PATH = os.path.join(CACHE_DIR, \"faiss_index.pkl\")\n",
    "HASH_PATH = os.path.join(CACHE_DIR, \"documents_hash.txt\")\n",
    "\n",
    "def hash_documents(documents):\n",
    "    # combine all the texts into a single string\n",
    "    all_titles = [doc.metadata['file_name'] for doc in documents]\n",
    "    all_titles_distinct = list(set(all_titles))\n",
    "    all_titles_distinct.sort()\n",
    "    all_titles_str = \" \".join(all_titles_distinct)\n",
    "    # return a hash of the combined text which will stay consistent if the text is the same across multiple runs\n",
    "    return hashlib.md5(all_titles_str.encode('utf-8')).hexdigest()\n",
    "\n",
    "def load_or_create_vector_store(documents, embed_dim, chunk_size, chunk_overlap):\n",
    "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "    \n",
    "    current_hash = hash_documents(documents)\n",
    "    \n",
    "    if os.path.exists(HASH_PATH) and os.path.exists(VECTOR_STORE_PATH):\n",
    "        with open(HASH_PATH, 'r') as f:\n",
    "            stored_hash = f.read().strip()\n",
    "\n",
    "        if stored_hash == current_hash:\n",
    "            print(\"Loading vector store from cache...\")\n",
    "            with open(VECTOR_STORE_PATH, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    \n",
    "    print(\"Creating new vector store...\")\n",
    "    faiss_index = faiss.IndexFlatL2(embed_dim)\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    \n",
    "    text_splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            TextCleaner(),\n",
    "            text_splitter,\n",
    "        ],\n",
    "        vector_store=vector_store,\n",
    "    )\n",
    "    \n",
    "    nodes = pipeline.run(documents=documents)\n",
    "    vector_store_index = VectorStoreIndex(nodes)\n",
    "    \n",
    "    # Save the new vector store and hash\n",
    "    with open(VECTOR_STORE_PATH, 'wb') as f:\n",
    "        pickle.dump(vector_store_index, f)\n",
    "    \n",
    "    with open(HASH_PATH, 'w') as f:\n",
    "        f.write(current_hash)\n",
    "    \n",
    "    return vector_store_index\n",
    "\n",
    "vector_store_index = load_or_create_vector_store(documents, EMBED_DIMENSION, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "retriever = vector_store_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_eval_test_cases(\n",
    "    questions: List[str],\n",
    "    gt_answers: List[str],\n",
    "    generated_answers: List[str],\n",
    "    retrieved_documents: List[str]\n",
    ") -> List[LLMTestCase]:\n",
    "    \"\"\"\n",
    "    Create a list of LLMTestCase objects for evaluation.\n",
    "\n",
    "    Args:\n",
    "        questions (List[str]): List of input questions.\n",
    "        gt_answers (List[str]): List of ground truth answers.\n",
    "        generated_answers (List[str]): List of generated answers.\n",
    "        retrieved_documents (List[str]): List of retrieved documents.\n",
    "\n",
    "    Returns:\n",
    "        List[LLMTestCase]: List of LLMTestCase objects.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        LLMTestCase(\n",
    "            input=question,\n",
    "            expected_output=gt_answer,\n",
    "            actual_output=generated_answer,\n",
    "            retrieval_context=retrieved_document\n",
    "        )\n",
    "        for question, gt_answer, generated_answer, retrieved_document in zip(\n",
    "            questions, gt_answers, generated_answers, retrieved_documents\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set llm model for evaluation of the question and answers \n",
    "LLM_MODEL = \"gpt-4o\"\n",
    "\n",
    "# Define evaluation metrics\n",
    "correctness_metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    model=LLM_MODEL,\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.EXPECTED_OUTPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT\n",
    "    ],\n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the actual output is factually correct based on the expected output.\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "faithfulness_metric = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=LLM_MODEL,\n",
    "    include_reason=False\n",
    ")\n",
    "\n",
    "relevance_metric = ContextualRelevancyMetric(\n",
    "    threshold=1,\n",
    "    model=LLM_MODEL,\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "def evaluate_rag(query_engine, num_questions: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate the RAG system using predefined metrics.\n",
    "\n",
    "    Args:\n",
    "        query_engine: Query engine to ask questions and get answers along with retrieved context.\n",
    "        num_questions (int): Number of questions to evaluate (default: 5).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Load questions and answers from JSON file\n",
    "    q_a_file_name = \"../data/q_a.json\"\n",
    "    with open(q_a_file_name, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        q_a = json.load(json_file)\n",
    "\n",
    "    questions = [qa[\"question\"] for qa in q_a][:num_questions]\n",
    "    ground_truth_answers = [qa[\"answer\"] for qa in q_a][:num_questions]\n",
    "    generated_answers = []\n",
    "    retrieved_documents = []\n",
    "\n",
    "    # Generate answers and retrieve documents for each question\n",
    "    for question in questions:\n",
    "        response = query_engine.query(question)\n",
    "        context = [doc.text for doc in response.source_nodes]\n",
    "        retrieved_documents.append(context)\n",
    "        generated_answers.append(response.response)\n",
    "\n",
    "    # Create test cases and evaluate\n",
    "    test_cases = create_deep_eval_test_cases(questions, ground_truth_answers, generated_answers, retrieved_documents)\n",
    "    evaluate(\n",
    "        test_cases=test_cases,\n",
    "        metrics=[correctness_metric, faithfulness_metric, relevance_metric]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Correctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mCorrectness \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 6 test case(s) in parallel: |██████████|100% (6/6) [Time Taken: 00:05,  1.07test case/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Correctness (GEval) (score: 0.7876717642674135, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output is mostly correct but omits the reason for the investment, which is to take advantage of the potential of AI., error: None)\n",
      "  - ✅ Faithfulness (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ❌ Contextual Relevancy (score: 0.5, threshold: 1.0, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because the context talks about investments in renewable energy, not compute clusters, as stated: 'The context discusses investments in renewable energy and North Sea incentives but does not mention any plans by the conservative party to invest in large-scale compute clusters.', error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How much is the conservative party planning to invest in large-scale compute clusters?\n",
      "  - actual output: The Conservative party is planning to invest over £1.5 billion in large-scale compute clusters.\n",
      "  - expected output: The conservative party is planning to invest £1.5 billion in large-scale compute clusters so they can take advantage of the potential of AI\n",
      "  - context: None\n",
      "  - retrieval context: ['In the next Parliament, we will:\\n ❱Increase public spending on R&D to £22 billion a year, up from £20 billion this year.\\n ❱Maintain our R&D tax reliefs. Recent changes worth £280 million a year have simplified and improved R&D tax reliefs, including by bringing more SMEs into scope of the relief.  ❱Continue investing over £1.5 billion in large-scale compute clusters, assembling the raw processing power so we can take advantage of the potential of AI and support research into its safe and responsible use.\\n ❱Push forward with our Advanced Manufacturing Plan, providing a £4.5 billion commitment to secure strategic manufacturing sectors including automotive, aerospace, life sciences and clean energy.', 'In total, this is expected to raise over £26 billion. We will maintain the investment allowances that provide incentives to invest in our North Sea, which Labour have said they would remove.\\nWe will back up renewables and prevent the prospect of blackouts with new gas power stations to maintain a safe and reliable energy source for days when the weather doesn’t power up renewables. Conservatives know that if we are forced to choose between clean energy and keeping citizens safe and warm, we will choose to keep the lights on. We are delivering record investment into UK renewables. But we need to go further, unlocking more investment to secure our energy supply in the future.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Correctness (GEval) (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output is factually correct and matches the expected output exactly., error: None)\n",
      "  - ✅ Faithfulness (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ✅ Contextual Relevancy (score: 1.0, threshold: 1.0, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the input is perfectly aligned with the context! Great job!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: By how much does the Green party promise to increase the disability benefits?\n",
      "  - actual output: The Green party promises to increase disability benefits by 5%.\n",
      "  - expected output: The Green party promises to increase disability benefits by 5%.\n",
      "  - context: None\n",
      "  - retrieval context: ['• Increase all disability benefits by 5%.\\n• Ensure that pensions are always uprated in line with inflation and keep pace with wage rises across the economy.\\n• Increase carer’s allowance by at least  10% a month. • Scrap the bedroom tax.In the long term, Green MPs will push for the introduction of a Universal Basic Income that will give everybody the security to start a business, study, train or just live their life in dignity. This major change to our tax and social security system is the work of more than one parliament.', 'The Joseph Rowntree Foundation estimate that 3.8 million people experienced destitution in 2022, including one million children.\\nWith the right political choices, we can do so much better – lifting everyone up and making sure all of us can access extra help if we need it.\\nElected Greens will campaign to: • Increase Universal Credit and legacy benefits by £40 a week.\\n• End the unfair five-week wait for benefits which is pushing people into debt.\\n• Abolish the two-child benefit cap and lift 250,000 children out of poverty.\\n• Increase all disability benefits by 5%.\\n• Ensure that pensions are always uprated in line with inflation and keep pace with wage rises across the economy.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Correctness (GEval) (score: 0.8932453309490211, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output correctly states the promise of gigabit broadband to every home and business in the UK but omits the '1' before 'gigabit'., error: None)\n",
      "  - ✅ Faithfulness (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ❌ Contextual Relevancy (score: 0.5, threshold: 1.0, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because the context discusses UK broadband goals generally, not specifically the Liberal Democrats' promises., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How much gigabit of broadband is the liberal democrats promising to provide to every home and business in the UK?\n",
      "  - actual output: The Liberal Democrats are promising to provide gigabit broadband to every home and business in the UK.\n",
      "  - expected output: The Liberal Democrats are promising to provide 1 gigabit of broadband to every home and business in the UK.\n",
      "  - context: None\n",
      "  - retrieval context: ['We have transformed our digital infrastructure by rolling out gigabit broadband to over a million hard to reach premises, helping to deliver high-speed internet to over 80% of the country. We are set to achieve at least 85% gigabit coverage of the UK by 2025 and nationwide coverage by 2030. Our ambition is for all populated areas to be covered by ‘standalone’ 5G mobile connectivity and to keep the UK at the forefront of adopting and developing 6G. We will spend £36 billion of HS2 savings on transport projects that will benefit more people, in more places, more quickly. Every penny saved in the North or Midlands will be spent there. Savings from our new plan for Euston,', '76\\nLiberal Democrat Election Manifesto 2024•  Ensure that gigabit broadband is available to every home and business, including in rural and remote communities, and support local bespoke solutions so that no property is left out.\\n•  End the top-down reorganisation of councils and the imposition of elected mayors on communities who do not want them.\\n•  Work with communities to tackle the alarming rise of antisemitism and Islamophobia.\\nIn addition, we will:\\n•  Decentralise decision-making from Whitehall and Westminster by inviting local areas to take control of the services that matter to them most.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.04586224840295896, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output incorrectly states the plan as building four new prisons instead of 10,000 new detention centres., error: None)\n",
      "  - ✅ Faithfulness (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ❌ Contextual Relevancy (score: 0.0, threshold: 1.0, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the context is focused on the policies of the Conservatives and Labour parties and does not mention the Reform UK party or their plans for detention centres., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How many detention centres does the Reform UK party plan to start building?\n",
      "  - actual output: The Reform UK party plans to start building four new prisons.\n",
      "  - expected output: The Reform UK party plans to start building 10,000 new detention centres.\n",
      "  - context: None\n",
      "  - retrieval context: ['We will prioritise further measures to crack down on hyper-prolific offenders. We will empower judges to require offenders to attend hearings or face an increased sentence. We will stand firmly behind the legal doctrine of joint enterprise meaning that those who assist in crimes, from the getaway driver to the weapon supplier, can be held accountable.  We will build four new prisons, completing our programme of 20,000 new prison places by 2030. We will make it easier to build prisons in appropriate places by scrapping legacy EU rules and streamlining the planning system. We will remove more Foreign National Offenders by increasing removals under the Early Removal Scheme and negotiating more Prisoner Transfer Agreements. We will maintain the ban on prisoners voting from jail.', 'The Conservatives’ unworkable laws have created a ‘perma-backlog’ of tens of thousands of asylum seekers, who are indefinitely staying in hotels costing the taxpayer millions of pounds every week.\\nLabour will stop the chaos and go after the criminal gangs who trade in driving this crisis. We will create a new Border Security Command, with hundreds of new investigators, intelligence officers, and cross-border police officers. This will be funded by ending the wasteful Migration and Economic Development partnership with Rwanda. This new Command will work internationally and be supported by new counter-terrorism style powers, to pursue, disrupt, and arrest those responsible for the vile trade.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Correctness (GEval) (score: 0.9970687768964114, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output accurately reflects the expected output by stating SNP's opposition to new nuclear power plants in Scotland., error: None)\n",
      "  - ✅ Faithfulness (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ✅ Contextual Relevancy (score: 1.0, threshold: 1.0, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the input perfectly matches the context, great job!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the SNP's policy on new nuclear plants in Scotland?\n",
      "  - actual output: The SNP's policy is to rule out new nuclear power plants in Scotland.\n",
      "  - expected output: The SNP is opposed to new nuclear plants in Scotland.\n",
      "  - context: None\n",
      "  - retrieval context: ['Only in this way, can as many jobs as possible be protected and the transition made to working on the new, greener technologies that offer a long-term future for the site..\\nRule out new nuclear power plants in Scotland. The SNP believe the best pathway to net zero and secure, affordable and clean energy is through significant growth in renewables, storage, hydrogen and carbon capture. Promote Scotland’s hydrogen export potential. Scotland is well placed to supply significant amounts of hydrogen to continental Europe.  SNP MPs will press for the UK Government to secure progress with direct interconnection between Scotland and the continent, and regulatory agreement to unlock Scotland’s renewable potential.', 'The future of the Grangemouth complex must be secured and a just transition delivered for the workforce. The UK Government must recognise the importance of the whole site to Scotland’s economy and communities and must invest in a sustainable future. Time is needed to unlock the significant opportunities for green industries of the future and it is important that the skilled workforce is retained, by extending refining for as long as possible, while that happens. Only in this way, can as many jobs as possible be protected and the transition made to working on the new, greener technologies that offer a long-term future for the site..\\nRule out new nuclear power plants in Scotland.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.17219380302744225, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output correctly mentions recruiting 6500 new teachers but incorrectly describes the funding method as reviewing bursaries and retention payments instead of ending tax breaks for private schools., error: None)\n",
      "  - ❌ Faithfulness (score: 0.5, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ❌ Contextual Relevancy (score: 0.0, threshold: 1.0, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the context describes recruitment strategies but lacks details on the financing of hiring 6,500 new teachers., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How is the Labour party planning to finance recruiting 6500 new teachers?\n",
      "  - actual output: The Labour party is planning to review the way bursaries are allocated and the structure of retention payments to finance recruiting 6,500 new teachers.\n",
      "  - expected output: The Labour party is planning to finance recruiting 6500 new teachers by ending tax breaks for private schools.\n",
      "  - context: None\n",
      "  - retrieval context: ['\\x07\\nL\\nabour\\n\\x07\\nwill\\n\\x07\\nrecruit\\n\\x07\\nan\\n\\x07\\nadditional \\x07\\n6\\n,500\\n\\x07\\nnew\\n\\x07\\nexpert\\n\\x07\\nteachers.\\n\\x07\\nWe\\n\\x07\\nwill\\x07\\ng\\net\\n\\x07\\nmore\\n\\x07\\nteachers\\n\\x07\\ninto\\n\\x07\\nshortage \\x07\\ns\\nubjects, support areas that face recruitment\\n\\x07\\nchallenges,\\n\\x07\\nand\\n\\x07\\ntackle\\x07\\nr\\netention\\n\\x07\\nissues.\\n\\x07\\nThe\\n\\x07\\nway\\n\\x07\\nbursaries \\x07\\nar\\ne allocated, and the structure of retention\\n\\x07\\npayments,\\n\\x07\\nwill\\n\\x07\\nbe\\n\\x07\\nreviewed.', 'We will attract more talented teachers by expanding our recruitment and retention premium and reducing workload. From this September, new teachers in priority areas and key STEM and technical subjects will receive bonuses of up to £30,000 tax-free over five years. We will extend the payments to eligible teachers in our further education colleges. We will always support and celebrate our further education colleges.\\nWe will champion excellence in our classrooms. In primary schools, we will support teachers to use tried and tested techniques, including our world-leading phonics programme and our mastery approach to maths, enabling every child to master the basics before they start secondary school.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Correctness (GEval): 66.67% pass rate\n",
      "Faithfulness: 83.33% pass rate\n",
      "Contextual Relevancy: 33.33% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to view evaluation results on Confident AI. \n",
       "‼️  NOTE: You can also run evaluations on ALL of deepeval's metrics directly on Confident AI instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to view evaluation results on Confident AI. \n",
       "‼️  NOTE: You can also run evaluations on ALL of deepeval's metrics directly on Confident AI instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine  = vector_store_index.as_query_engine(similarity_top_k=2)\n",
    "evaluate_rag(query_engine, num_questions=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
