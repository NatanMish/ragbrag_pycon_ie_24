{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/ragbrag_pycon_ie_24/venv/lib/python3.10/site-packages/deepeval/__init__.py:49: UserWarning: You are using deepeval version 1.2.9, however version 1.3.5 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n",
      "/Users/user/Projects/ragbrag_pycon_ie_24/venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.schema import BaseNode, TransformComponent\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "import faiss\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "\n",
    "EMBED_DIMENSION = 512\n",
    "CHUNK_SIZE = 250\n",
    "CHUNK_OVERLAP = 25\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set embedding model on LlamaIndex global settings\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=EMBED_DIMENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 71419e08-91cf-4966-a1d6-7e6a5fb8b20f\n",
      "Text: Promoted by SNP 3 Jacksons Entry EH8 8PJ. Printed by Saltire 60\n",
      "Brook Street G40 2AB.“A FUTURE    MADE IN    SCOTLAND.” VOTE SNP  FOR\n",
      "SCOTLAND\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/\"\n",
    "node_parser = SimpleDirectoryReader(input_dir=path, required_exts=['.txt', '.pdf'])\n",
    "documents = node_parser.load_data()\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaner Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(TransformComponent):\n",
    "    \"\"\"\n",
    "    Transformation to be used within the ingestion pipeline.\n",
    "    Cleans clutters from texts.\n",
    "    \"\"\"\n",
    "    def __call__(self, nodes, **kwargs) -> List[BaseNode]:\n",
    "        \n",
    "        for node in nodes:\n",
    "            node.text = node.text.replace('\\t', ' ') # Replace tabs with spaces\n",
    "            node.text = node.text.replace(' \\n', ' ') # Replace paragraph seperator with spacaes\n",
    "            \n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_documents(documents):\n",
    "    # combine all the texts into a single string\n",
    "    all_titles = [doc.metadata['file_name'] for doc in documents]\n",
    "    all_titles_distinct = list(set(all_titles))\n",
    "    all_titles_distinct.sort()\n",
    "    all_titles_str = \" \".join(all_titles_distinct)\n",
    "    # return a hash of the combined text which will stay consistent if the text is the same across multiple runs\n",
    "    return hashlib.md5(all_titles_str.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"../cache\"\n",
    "VECTOR_STORE_PATH = os.path.join(CACHE_DIR, \"faiss_index.pkl\")\n",
    "HASH_PATH = os.path.join(CACHE_DIR, \"documents_hash.txt\")\n",
    "\n",
    "def load_or_create_vector_store(documents, embed_dim, chunk_size, chunk_overlap):\n",
    "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "    \n",
    "    current_hash = hash_documents(documents)\n",
    "    \n",
    "    if os.path.exists(HASH_PATH) and os.path.exists(VECTOR_STORE_PATH):\n",
    "        with open(HASH_PATH, 'r') as f:\n",
    "            stored_hash = f.read().strip()\n",
    "\n",
    "        if stored_hash == current_hash:\n",
    "            print(\"Loading vector store from cache...\")\n",
    "            with open(VECTOR_STORE_PATH, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    \n",
    "    print(\"Creating new vector store...\")\n",
    "    faiss_index = faiss.IndexFlatL2(embed_dim)\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    \n",
    "    text_splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            TextCleaner(),\n",
    "            text_splitter,\n",
    "        ],\n",
    "        vector_store=vector_store,\n",
    "    )\n",
    "    \n",
    "    nodes = pipeline.run(documents=documents)\n",
    "    vector_store_index = VectorStoreIndex(nodes)\n",
    "    \n",
    "    # Save the new vector store and hash\n",
    "    with open(VECTOR_STORE_PATH, 'wb') as f:\n",
    "        pickle.dump(vector_store_index, f)\n",
    "    \n",
    "    with open(HASH_PATH, 'w') as f:\n",
    "        f.write(current_hash)\n",
    "    \n",
    "    return vector_store_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Removing unpickleable private attribute _client\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n"
     ]
    }
   ],
   "source": [
    "vector_store_index = load_or_create_vector_store(documents, EMBED_DIMENSION, CHUNK_SIZE, CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_context(context):\n",
    "    \"\"\"\n",
    "    Display the contents of the provided context list.\n",
    "\n",
    "    Args:\n",
    "        context (list): A list of context items to be displayed.\n",
    "\n",
    "    Prints each context item in the list with a heading indicating its position.\n",
    "    \"\"\"\n",
    "    for i, c in enumerate(context):\n",
    "        print(f\"Context {i+1}:\")\n",
    "        print(c.text)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "20BUILDING A FAIRER, GREENER ECONOMY Under the SNP, Scotland’s economy is already one of the best performing parts of the UK with both GDP per head and productivity growing faster in Scotland than the UK as a whole.  But we want to go further. Our commitment to tackling the twin crises of climate change and nature loss is unwavering and we believe emissions reduction and economic prosperity go hand in hand. We want  to share in the enormous economic opportunities of the global transition to net zero. SNP MPs will demand the UK Government:\n",
      "Bring forward an immediate emergency budget following the election to reverse cuts to public spending and deliver meaningful investment in economic growth, including green energy.\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Only in this way, can as many jobs as possible be protected and the transition made to working on the new, greener technologies that offer a long-term future for the site..\n",
      "Rule out new nuclear power plants in Scotland. The SNP believe the best pathway to net zero and secure, affordable and clean energy is through significant growth in renewables, storage, hydrogen and carbon capture. Promote Scotland’s hydrogen export potential. Scotland is well placed to supply significant amounts of hydrogen to continental Europe.  SNP MPs will press for the UK Government to secure progress with direct interconnection between Scotland and the continent, and regulatory agreement to unlock Scotland’s renewable potential.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the SNP's policy on climate change?\"\n",
    "context = retriever.retrieve(test_query)\n",
    "show_context(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
