{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/ragbrag_pycon_ie_24/venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.schema import BaseNode, TransformComponent\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "import faiss\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "\n",
    "EMBED_DIMENSION = 512\n",
    "\n",
    "# Chunk settings are way different than langchain examples\n",
    "# Beacuse for the chunk length langchain uses length of the string,\n",
    "# while llamaindex uses length of the tokens\n",
    "CHUNK_SIZE = 200\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set embeddig model on LlamaIndex global settings\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=EMBED_DIMENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 6df28fbd-657d-4af2-a738-5a11cd85fd42\n",
      "Text: Promoted by SNP 3 Jacksons Entry EH8 8PJ. Printed by Saltire 60\n",
      "Brook Street G40 2AB.“A FUTURE    MADE IN    SCOTLAND.” VOTE SNP  FOR\n",
      "SCOTLAND\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/\"\n",
    "node_parser = SimpleDirectoryReader(input_dir=path, required_exts=['.txt', '.pdf'])\n",
    "documents = node_parser.load_data()\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FaisVectorStore to store embeddings\n",
    "faiss_index = faiss.IndexFlatL2(EMBED_DIMENSION)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaner Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(TransformComponent):\n",
    "    \"\"\"\n",
    "    Transformation to be used within the ingestion pipeline.\n",
    "    Cleans clutters from texts.\n",
    "    \"\"\"\n",
    "    def __call__(self, nodes, **kwargs) -> List[BaseNode]:\n",
    "        \n",
    "        for node in nodes:\n",
    "            node.text = node.text.replace('\\t', ' ') # Replace tabs with spaces\n",
    "            node.text = node.text.replace(' \\n', ' ') # Replace paragraph seperator with spacaes\n",
    "            \n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "\n",
    "# Create a pipeline with defined document transformations and vectorstore\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        TextCleaner(),\n",
    "        text_splitter,\n",
    "    ],\n",
    "    vector_store=vector_store, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline and get generated nodes from the process\n",
    "nodes = pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_index = VectorStoreIndex(nodes)\n",
    "retriever = vector_store_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_context(context):\n",
    "    \"\"\"\n",
    "    Display the contents of the provided context list.\n",
    "\n",
    "    Args:\n",
    "        context (list): A list of context items to be displayed.\n",
    "\n",
    "    Prints each context item in the list with a heading indicating its position.\n",
    "    \"\"\"\n",
    "    for i, c in enumerate(context):\n",
    "        print(f\"Context {i+1}:\")\n",
    "        print(c.text)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "20BUILDING A FAIRER, GREENER ECONOMY Under the SNP, Scotland’s economy is already one of the best performing parts of the UK with both GDP per head and productivity growing faster in Scotland than the UK as a whole.  But we want to go further. Our commitment to tackling the twin crises of climate change and nature loss is unwavering and we believe emissions reduction and economic prosperity go hand in hand. We want  to share in the enormous economic opportunities of the global transition to net zero. SNP MPs will demand the UK Government:\n",
      "Bring forward an immediate emergency budget following the election to reverse cuts to public spending and deliver meaningful investment in economic growth, including green energy.\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Only in this way, can as many jobs as possible be protected and the transition made to working on the new, greener technologies that offer a long-term future for the site..\n",
      "Rule out new nuclear power plants in Scotland. The SNP believe the best pathway to net zero and secure, affordable and clean energy is through significant growth in renewables, storage, hydrogen and carbon capture. Promote Scotland’s hydrogen export potential. Scotland is well placed to supply significant amounts of hydrogen to continental Europe.  SNP MPs will press for the UK Government to secure progress with direct interconnection between Scotland and the continent, and regulatory agreement to unlock Scotland’s renewable potential.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the SNP's policy on climate change?\"\n",
    "context = retriever.retrieve(test_query)\n",
    "show_context(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how well does it perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval, FaithfulnessMetric, ContextualRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCaseParams, LLMTestCase\n",
    "\n",
    "def create_deep_eval_test_cases(\n",
    "    questions: List[str],\n",
    "    gt_answers: List[str],\n",
    "    generated_answers: List[str],\n",
    "    retrieved_documents: List[str]\n",
    ") -> List[LLMTestCase]:\n",
    "    \"\"\"\n",
    "    Create a list of LLMTestCase objects for evaluation.\n",
    "\n",
    "    Args:\n",
    "        questions (List[str]): List of input questions.\n",
    "        gt_answers (List[str]): List of ground truth answers.\n",
    "        generated_answers (List[str]): List of generated answers.\n",
    "        retrieved_documents (List[str]): List of retrieved documents.\n",
    "\n",
    "    Returns:\n",
    "        List[LLMTestCase]: List of LLMTestCase objects.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        LLMTestCase(\n",
    "            input=question,\n",
    "            expected_output=gt_answer,\n",
    "            actual_output=generated_answer,\n",
    "            retrieval_context=retrieved_document\n",
    "        )\n",
    "        for question, gt_answer, generated_answer, retrieved_document in zip(\n",
    "            questions, gt_answers, generated_answers, retrieved_documents\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set llm model for evaluation of the question and answers \n",
    "LLM_MODEL = \"gpt-4o\"\n",
    "\n",
    "# Define evaluation metrics\n",
    "correctness_metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    model=LLM_MODEL,\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.EXPECTED_OUTPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT\n",
    "    ],\n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the actual output is factually correct based on the expected output.\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "faithfulness_metric = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=LLM_MODEL,\n",
    "    include_reason=False\n",
    ")\n",
    "\n",
    "relevance_metric = ContextualRelevancyMetric(\n",
    "    threshold=1,\n",
    "    model=LLM_MODEL,\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "def evaluate_rag(query_engine, num_questions: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate the RAG system using predefined metrics.\n",
    "\n",
    "    Args:\n",
    "        query_engine: Query engine to ask questions and get answers along with retrieved context.\n",
    "        num_questions (int): Number of questions to evaluate (default: 5).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Load questions and answers from JSON file\n",
    "    q_a_file_name = \"../data/q_a.json\"\n",
    "    with open(q_a_file_name, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        q_a = json.load(json_file)\n",
    "\n",
    "    questions = [qa[\"question\"] for qa in q_a][:num_questions]\n",
    "    ground_truth_answers = [qa[\"answer\"] for qa in q_a][:num_questions]\n",
    "    generated_answers = []\n",
    "    retrieved_documents = []\n",
    "\n",
    "    # Generate answers and retrieve documents for each question\n",
    "    for question in questions:\n",
    "        response = query_engine.query(question)\n",
    "        context = [doc.text for doc in response.source_nodes]\n",
    "        retrieved_documents.append(context)\n",
    "        generated_answers.append(response.response)\n",
    "\n",
    "    # Create test cases and evaluate\n",
    "    test_cases = create_deep_eval_test_cases(questions, ground_truth_answers, generated_answers, retrieved_documents)\n",
    "    evaluate(\n",
    "        test_cases=test_cases,\n",
    "        metrics=[correctness_metric, faithfulness_metric, relevance_metric]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Correctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mCorrectness \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:10, 10.14s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.22760030266648318, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output mentions tackling climate change and net zero but lacks specific targets like 2045 net zero and 75% by 2030 mentioned in the expected output., error: None)\n",
      "  - ✅ Faithfulness (score: 0.8333333333333334, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ❌ Contextual Relevancy (score: 0.5, threshold: 1.0, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because the context discusses Scotland's peatland and related climate actions, but it does not directly address the SNP's policy on climate change., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the snp's policy on climate change?\n",
      "  - actual output: The SNP's policy on climate change involves a commitment to tackling climate change and nature loss, believing that emissions reduction and economic prosperity are interconnected. They aim to share in the economic opportunities of the global transition to net zero and demand fair funding from the UK Government to support Scotland's climate ambitions. Additionally, they advocate for the establishment of a Four Nations Climate Response Group to coordinate climate plans across the UK and ensure the UK Government maintains its climate ambition without backtracking.\n",
      "  - expected output: Achieving net zero emissions by 2045, Reducing emissions by 75% by 2030. They emphasize Scotland's role as a global leader in tackling climate change.\n",
      "  - context: None\n",
      "  - retrieval context: ['20BUILDING A FAIRER, GREENER ECONOMY Under the SNP, Scotland’s economy is already one of the best performing parts of the UK with both GDP per head and productivity growing faster in Scotland than the UK as a whole.  But we want to go further. Our commitment to tackling the twin crises of climate change and nature loss is unwavering and we believe emissions reduction and economic prosperity go hand in hand. We want  to share in the enormous economic opportunities of the global transition to net zero. SNP MPs will demand the UK Government:\\nBring forward an immediate emergency budget following the election to reverse cuts to public spending and deliver meaningful investment in economic growth, including green energy.', 'Scotland has over two thirds of the UK’s peatland, and currently plants over 60% of trees in the UK, yet funds restoration and planting within our budget, with no help from the UK Government. Westminster must ensure fair funding flows to devolved nations to enable our, and their, climate ambition given that for the whole of the UK to reach net zero by 2050, Scotland must do so  by 2045.\\nEstablish a Four Nations Climate Response Group to agree climate plans across the UK  that deliver on our net-zero targets and ensure  the UK Government stops backtracking on climate ambition.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Correctness (GEval): 0.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "Contextual Relevancy: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to view evaluation results on Confident AI. \n",
       "‼️  NOTE: You can also run evaluations on ALL of deepeval's metrics directly on Confident AI instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to view evaluation results on Confident AI. \n",
       "‼️  NOTE: You can also run evaluations on ALL of deepeval's metrics directly on Confident AI instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine  = vector_store_index.as_query_engine(similarity_top_k=2)\n",
    "evaluate_rag(query_engine, num_questions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
