{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothetical Document Embedding (HyDE)\n",
    "\n",
    "### Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vector store from cache...\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.schema import BaseNode, TransformComponent\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import faiss\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "EMBED_DIMENSION = 512\n",
    "CHUNK_SIZE = 200\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=EMBED_DIMENSION)\n",
    "\n",
    "path = \"../data/\"\n",
    "node_parser = SimpleDirectoryReader(input_dir=path, required_exts=['.txt', '.pdf'])\n",
    "documents = node_parser.load_data()\n",
    "### Set up vector store retriever\n",
    "class TextCleaner(TransformComponent):\n",
    "    \"\"\"\n",
    "    Transformation to be used within the ingestion pipeline.\n",
    "    Cleans clutters from texts.\n",
    "    \"\"\"\n",
    "    def __call__(self, nodes, **kwargs) -> List[BaseNode]:\n",
    "        \n",
    "        for node in nodes:\n",
    "            node.text = node.text.replace('\\t', ' ') # Replace tabs with spaces\n",
    "            node.text = node.text.replace(' \\n', ' ') # Replace paragraph seperator with spacaes\n",
    "            \n",
    "        return nodes\n",
    "CACHE_DIR = \"../cache\"\n",
    "VECTOR_STORE_PATH = os.path.join(CACHE_DIR, \"faiss_index.pkl\")\n",
    "HASH_PATH = os.path.join(CACHE_DIR, \"documents_hash.txt\")\n",
    "\n",
    "def hash_documents(documents):\n",
    "    # combine all the texts into a single string\n",
    "    all_titles = [doc.metadata['file_name'] for doc in documents]\n",
    "    all_titles_distinct = list(set(all_titles))\n",
    "    all_titles_distinct.sort()\n",
    "    all_titles_str = \" \".join(all_titles_distinct)\n",
    "    # return a hash of the combined text which will stay consistent if the text is the same across multiple runs\n",
    "    return hashlib.md5(all_titles_str.encode('utf-8')).hexdigest()\n",
    "\n",
    "def load_or_create_vector_store(documents, embed_dim, chunk_size, chunk_overlap):\n",
    "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "    \n",
    "    current_hash = hash_documents(documents)\n",
    "    \n",
    "    if os.path.exists(HASH_PATH) and os.path.exists(VECTOR_STORE_PATH):\n",
    "        with open(HASH_PATH, 'r') as f:\n",
    "            stored_hash = f.read().strip()\n",
    "\n",
    "        if stored_hash == current_hash:\n",
    "            print(\"Loading vector store from cache...\")\n",
    "            with open(VECTOR_STORE_PATH, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    \n",
    "    print(\"Creating new vector store...\")\n",
    "    faiss_index = faiss.IndexFlatL2(embed_dim)\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    \n",
    "    text_splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            TextCleaner(),\n",
    "            text_splitter,\n",
    "        ],\n",
    "        vector_store=vector_store,\n",
    "    )\n",
    "    \n",
    "    nodes = pipeline.run(documents=documents)\n",
    "    vector_store_index = VectorStoreIndex(nodes)\n",
    "    \n",
    "    # Save the new vector store and hash\n",
    "    with open(VECTOR_STORE_PATH, 'wb') as f:\n",
    "        pickle.dump(vector_store_index, f)\n",
    "    \n",
    "    with open(HASH_PATH, 'w') as f:\n",
    "        f.write(current_hash)\n",
    "    \n",
    "    return vector_store_index\n",
    "\n",
    "vector_store_index = load_or_create_vector_store(documents, EMBED_DIMENSION, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "retriever = vector_store_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module d1cffccb-c461-441d-a960-4c3e86dcf190 with input: \n",
      "query: What is the SNP's policy on climate change?\n",
      "chunk_size: ../data/\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 58e458de-301b-485e-a4ea-336b872cd024 with input: \n",
      "messages: Given the question 'What is the SNP's policy on climate change?', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
      "            the do...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='d0d6edf8-e094-432b-8dae-eadf23fb70a2', embedding=None, metadata={'page_label': '22', 'file_name': '2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_path': '/Users/user/Projects/ragbrag_pycon_ie_24/notebooks/../data/2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_type': 'application/pdf', 'file_size': 3559498, 'creation_date': '2024-09-24', 'last_modified_date': '2024-09-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='60ca30b3-62aa-46d9-bf0c-25fe52165bcb', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '22', 'file_name': '2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_path': '/Users/user/Projects/ragbrag_pycon_ie_24/notebooks/../data/2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_type': 'application/pdf', 'file_size': 3559498, 'creation_date': '2024-09-24', 'last_modified_date': '2024-09-24'}, hash='5b5c1bd65139116412ad899c373f246a012404e4138f193a0cbf3bd2ae3a1e7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='95060ddc-9708-4464-b673-d01acc480788', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='de0cb49c5d3b2cb19201ae536411bbd1abf300946a135050bb2d6b2d97c4e5dd')}, text='20BUILDING A FAIRER, GREENER ECONOMY Under the SNP, Scotlandâ€™s economy is already one of the best performing parts of the UK with both GDP per head and productivity growing faster in Scotland than the UK as a whole.  But we want to go further. Our commitment to tackling the twin crises of climate change and nature loss is unwavering and we believe emissions reduction and economic prosperity go hand in hand. We want  to share in the enormous economic opportunities of the global transition to net zero. SNP MPs will demand the UK Government:\\nBring forward an immediate emergency budget following the election to reverse cuts to public spending and deliver meaningful investment in economic growth, including green energy.', mimetype='text/plain', start_char_idx=0, end_char_idx=724, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6060863998362345),\n",
       " NodeWithScore(node=TextNode(id_='5146c421-ddae-4aa9-967c-c5cd4a2f027b', embedding=None, metadata={'page_label': '22', 'file_name': '2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_path': '/Users/user/Projects/ragbrag_pycon_ie_24/notebooks/../data/2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_type': 'application/pdf', 'file_size': 3559498, 'creation_date': '2024-09-24', 'last_modified_date': '2024-09-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='60ca30b3-62aa-46d9-bf0c-25fe52165bcb', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '22', 'file_name': '2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_path': '/Users/user/Projects/ragbrag_pycon_ie_24/notebooks/../data/2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_type': 'application/pdf', 'file_size': 3559498, 'creation_date': '2024-09-24', 'last_modified_date': '2024-09-24'}, hash='5b5c1bd65139116412ad899c373f246a012404e4138f193a0cbf3bd2ae3a1e7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='878c7097-01c0-4731-a7b4-5f4a3f616655', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '22', 'file_name': '2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_path': '/Users/user/Projects/ragbrag_pycon_ie_24/notebooks/../data/2024-06-20b-SNP-General-Election-Manifesto-2024_interactive.pdf', 'file_type': 'application/pdf', 'file_size': 3559498, 'creation_date': '2024-09-24', 'last_modified_date': '2024-09-24'}, hash='d5f8a529719c338d434b09e660254678e6cf55044edd762e1b3bad0642ec615f')}, text='Only in this way, can as many jobs as possible be protected and the transition made to working on the new, greener technologies that offer a long-term future for the site..\\nRule out new nuclear power plants in Scotland. The SNP believe the best pathway to net zero and secure, affordable and clean energy is through significant growth in renewables, storage, hydrogen and carbon capture. Promote Scotlandâ€™s hydrogen export potential. Scotland is well placed to supply significant amounts of hydrogen to continental Europe.  SNP MPs will press for the UK Government to secure progress with direct interconnection between Scotland and the continent, and regulatory agreement to unlock Scotlandâ€™s renewable potential.', mimetype='text/plain', start_char_idx=2484, end_char_idx=3198, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5935799091745326)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HyDERetriever:\n",
    "    def __init__(self, chunk_size=250, chunk_overlap=50):\n",
    "        self.llm = OpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "        self.embeddings = Settings.embed_model\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vectore_store_retriever = retriever    \n",
    "        \n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            \"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "            the document size has be exactly {chunk_size} characters.\"\"\",\n",
    "        )\n",
    "        self.hyde_chain = QueryPipeline(chain=[self.hyde_prompt, self.llm], verbose=True)\n",
    "\n",
    "    def generate_hypothetical_document(self, query):\n",
    "        return self.hyde_chain.run(query=query, chunk_size=self.chunk_size)\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectore_store_retriever.retrieve(query)\n",
    "        return similar_docs, hypothetical_doc\n",
    "\n",
    "hyde_retriever = HyDERetriever(path)\n",
    "test_query = \"What is the SNP's policy on climate change?\"\n",
    "results, hypothetical_doc = hyde_retriever.retrieve(test_query)\n",
    "hypothetical_doc\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
